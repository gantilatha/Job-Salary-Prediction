{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 4 : Job Market Analysis\n",
    "## Notebook 04: Predective Modelling - Classification Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegressionCV, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from scipy import interp\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_jobs = pd.read_csv('final_jobs.csv', index_col = [0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_jobs.head();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Giving the range for salaries:\n",
    "Here I am giving a rank to the salaries as there are very few observations left for analysis with a range staring from 40000 to 500000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def salary_Rank(salary_range):\n",
    "    if salary_range <= 40000:\n",
    "        return 0\n",
    "    elif salary_range > 40000 and salary_range <= 120000:\n",
    "        return 1\n",
    "    elif salary_range > 120000 and salary_range <= 180000:\n",
    "        return 2\n",
    "    else:\n",
    "        return 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_jobs['salary_rank'] = final_jobs['final_salary'].map(lambda x : salary_Rank(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline accuracy is: 3    0.366142\n",
      "1    0.327559\n",
      "2    0.306299\n",
      "Name: salary_rank, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "final_jobs.salary_rank.value_counts(normalize =True)\n",
    "print('Baseline accuracy is:', final_jobs.salary_rank.value_counts(normalize =True))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coding dummy variables:\n",
    "Creating dummy variables for the categorical features so I can use them for moddeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_jobs_subset = final_jobs[['new_job_category','new_job_title','experience_level','job_location','type_of_work']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_jobs_subset.head();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols = pd.get_dummies(final_jobs_subset, drop_first=True, prefix=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_cols.columns;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = final_cols\n",
    "y = final_jobs['salary_rank']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Standardizing the dataframe\n",
    "Standarzing the data will make the dataset ready for modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\MyPrograms\\Anaconda3\\lib\\site-packages\\sklearn\\preprocessing\\data.py:625: DataConversionWarning: Data with input dtype uint8 were all converted to float64 by StandardScaler.\n",
      "  return self.partial_fit(X, y)\n",
      "C:\\MyPrograms\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:462: DataConversionWarning: Data with input dtype uint8 were all converted to float64 by StandardScaler.\n",
      "  return self.fit(X, **fit_params).transform(X)\n"
     ]
    }
   ],
   "source": [
    "ss = StandardScaler()\n",
    "Xn = ss.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the DataFrame to train and test\n",
    "\n",
    "Here I split my data into a train and test set. I will be training all my models on the training set and testing on the test set. This will give me the best idea of how well generalized my model is. I opted with a training set size of 70%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y, test_size = 0.3, random_state = 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(889, 13) (889,)\n",
      "(381, 13) (381,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling:\n",
    "\n",
    "# Logistic Regression:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(random_state=0, solver='lbfgs', multi_class='multinomial')\n",
    "logreg.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of train: 75.47806524184477\n",
      "The accuracy score of test: 75.32808398950131\n"
     ]
    }
   ],
   "source": [
    "y_pred = logreg.predict(X_test)\n",
    "print(\"The accuracy score of train:\", logreg.score(X_train, y_train)*100)\n",
    "print(\"The accuracy score of test:\", logreg.score(X_test, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg.coef_;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Precision and recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.73      0.76      0.75       127\n",
      "           2       0.72      0.67      0.70       119\n",
      "           3       0.80      0.81      0.81       135\n",
      "\n",
      "   micro avg       0.75      0.75      0.75       381\n",
      "   macro avg       0.75      0.75      0.75       381\n",
      "weighted avg       0.75      0.75      0.75       381\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Prec_score = metrics.classification_report(y_test, y_pred)\n",
    "print(Prec_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accuracy score of train: 71.65354330708661\n",
      "The accuracy score of test: 72.17847769028872\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=42)\n",
    "clf.fit(X, y)\n",
    "clf.predict(X_test)\n",
    "print(\"The accuracy score of train:\", clf.score(X_train, y_train)*100)\n",
    "print(\"The accuracy score of test:\", clf.score(X_test, y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0105468  0.19480575 0.03090298 0.04670903 0.08229094 0.02054389\n",
      " 0.01999971 0.00154971 0.00435975 0.00512396 0.3535372  0.22862125\n",
      " 0.00100902]\n"
     ]
    }
   ],
   "source": [
    "print(clf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of the features and their importance scores\n",
    "list_features = list(zip(X_train, clf.feature_importances_ ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('new_job_category_Gov_Services', 0.010546796192119769),\n",
       " ('new_job_category_Information Technology', 0.19480575259113656),\n",
       " ('new_job_category_Others', 0.030902981040653102),\n",
       " ('new_job_category_Sales & Marketing', 0.046709029547904776),\n",
       " ('new_job_title_data analyst', 0.08229094039575054),\n",
       " ('new_job_title_data manager', 0.020543894107030832),\n",
       " ('new_job_title_data scientist', 0.019999713233578485),\n",
       " ('experience_level_Mid_level', 0.0015497065609627336),\n",
       " ('experience_level_Senior_level', 0.00435975173795949),\n",
       " ('job_location_All-Sydney-NSW', 0.0051239631446125785),\n",
       " ('type_of_work_Contract/Temp', 0.3535372030700916),\n",
       " ('type_of_work_Full Time', 0.22862125263146105),\n",
       " ('type_of_work_Part Time', 0.0010090157467385027)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Observation:\n",
    "\n",
    "The models I used for classification are Logistic Regression and Random Forest. Below are few observations:\n",
    "1. Both the models are giving better results.\n",
    "2. The precision and Recall for 3 says that 80% of the observations are true positives.\n",
    "3. The top impacters are almost the same as predicted in regression model: \n",
    "    - Work Type (Contract/Temp, Full Time)\n",
    "    - Category(Industry) (Information Technology)\n",
    "    - Job Title (Data Analyst)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
