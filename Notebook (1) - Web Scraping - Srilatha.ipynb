{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 4 : Job Market Analysis\n",
    "\n",
    "## Notebook 01 : Data Extraction from Seek - (Web Scrape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this project is to answer the following questions:\n",
    "\n",
    "Identify the factors that have the most affect on salary? Identify the key skills and buzzwords across job category / title?\n",
    "\n",
    "For the analysis, I have gathered data from the job search engine site SEEK Limited AU. I have limited the study to data related fields like data scientist, data analyst for Sydney and Melbourne."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scrapy.selector import Selector\n",
    "from scrapy.http import HtmlResponse\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import pdb\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.width', 1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code will scrape the data from the job site SEEK.com.au by using Xpath and a combination of Beautiful Soup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def page(url):\n",
    "    request = requests.get(url)\n",
    "  \n",
    "    if request.status_code == 200:\n",
    "        select_data = Selector(text=request.text)\n",
    "        # Extract Title of the job\n",
    "        pdb.set_trace()\n",
    "        job_title = select_data.xpath('//*/*[@*=\"job-detail-title\"]/span/h1/text()').extract()[0] \n",
    "        # Extract Advertiser / company name\n",
    "        advertiser = select_data.xpath('//*/h2/span/span/text()').extract()            \n",
    "        \n",
    "        if len(advertiser) > 0:\n",
    "            advertiser = advertiser[0]\n",
    "        else:\n",
    "            advertiser = None\n",
    "        # Extract Rating of the advertise if any\n",
    "        rating = select_data.xpath('//*/h2/span/span/span/span/text()').extract()         \n",
    "        if len(rating) > 0:\n",
    "            rating = rating[0]\n",
    "        else:\n",
    "            rating = None\n",
    "        # Extract job Posted Date\n",
    "        posted_date = select_data.xpath('//*/*[@*=\"job-detail-date\"]/span/span/text()').extract()[0] \n",
    "        # Extract Salary\n",
    "        salary = select_data.xpath('//*/*[@*=\"jobInfoHeader\"]/dl/div/dd/span/span/text()').extract() \n",
    "        \n",
    "        if len(salary) > 0:\n",
    "            salary = salary[0]\n",
    "        else:\n",
    "            salary = None\n",
    "      \n",
    "        # Extract Contract Type\n",
    "        type_of_work = select_data.xpath('//*/*[@*=\"job-detail-work-type\"]/span/span/text()').extract()[0] \n",
    "        # Extract Job Category\n",
    "        category_of_work = select_data.xpath('//*/section[@*=\"jobInfoHeader\"]/dl/div/dd/span/span/strong/text()').extract()[0] \n",
    "        # Extract if there's any sub Category\n",
    "        sub_category_of_work = select_data.xpath('//*/section[@*=\"jobInfoHeader\"]/dl/div/dd/span/span/span/text()').extract()[0] \n",
    "    \n",
    "    # Extracting the Job description text:\n",
    "        parsed_results = BeautifulSoup(request.text, 'lxml')\n",
    "       \n",
    "        body_text = parsed_results.find('div', {'data-automation': 'mobileTemplate'}).text\n",
    "    \n",
    "        return job_title, advertiser, rating, posted_date, salary, type_of_work, category_of_work, sub_category_of_work, body_text\n",
    "  \n",
    "    else:\n",
    "        print('Failed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jobs_scraped(job, location, res_page=20):\n",
    "    scraped_results = {'job_title' : [],\n",
    "               'job_location': [],\n",
    "                'advertiser' : [],\n",
    "                'rating' : [],\n",
    "                'posted_date' : [],\n",
    "                'salary' : [],\n",
    "                'type_of_work' : [],\n",
    "                'job_category' : [],\n",
    "                'job_subcategory' : [],\n",
    "                'job_description' : [],\n",
    "                'job_searched' : [],\n",
    "                'url' : []\n",
    "       }\n",
    "\n",
    "    url = 'https://www.seek.com.au/' + job + '-jobs/in-' + location\n",
    "    request = requests.get(url)\n",
    "    select_data = Selector(text=request.text)\n",
    "    total_results = np.ceil(int(select_data.xpath('//*/*[@*=\"totalJobsCount\"]/text()').extract()[0].replace(',','')) / 20)\n",
    "    total_results = int(total_results)\n",
    "  \n",
    "    for i in range(1,total_results + 1):\n",
    "        url = 'https://www.seek.com.au/' + job + '-jobs/in-' + location + '?page=' + str(i)\n",
    "        request = requests.get(url)\n",
    "        select_data = Selector(text=request.text)\n",
    "        h_refs = select_data.xpath('//*/*[@*=\"searchResults\"]/div/div/div/article/span/span/h1/a/@href').extract()\n",
    "   \n",
    "        for h_ref in h_refs:\n",
    "            url = 'https://www.seek.com.au' + h_ref\n",
    "            job_title, advertiser, rating, posted_date, salary, type_of_work, category_of_work, sub_category_of_work, body_of_text = page(url)\n",
    "            scraped_results['job_title'].append(job_title)\n",
    "            scraped_results['job_searched'].append(job)\n",
    "            scraped_results['job_location'].append(location)\n",
    "            scraped_results['advertiser'].append(advertiser)\n",
    "            scraped_results['rating'].append(rating)\n",
    "            scraped_results['posted_date'].append(posted_date)\n",
    "            scraped_results['salary'].append(salary)\n",
    "            scraped_results['type_of_work'].append(type_of_work)\n",
    "            scraped_results['job_category'].append(category_of_work)\n",
    "            scraped_results['job_subcategory'].append(sub_category_of_work)\n",
    "            scraped_results['job_description'].append(body_of_text)\n",
    "            scraped_results['url'].append(url)\n",
    "      \n",
    "    return pd.DataFrame(scraped_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Individual Page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> <ipython-input-4-9f8336b6204e>(8)page()\n",
      "-> job_title = select_data.xpath('//*/*[@*=\"job-detail-title\"]/span/h1/text()').extract()[0]\n",
      "(Pdb) select_data\n",
      "<Selector xpath=None data='<html lang=\"en\" prefix=\"og: http://ogp.m'>\n",
      "(Pdb) select_data.xpath('//*/*[@*=\"job-detail-title\"]/span/h1/text()').extract()[0]\n",
      "'Trainee Data Analyst'\n",
      "(Pdb) select_data.xpath('//*/h2/span/span/text()').extract() \n",
      "['Roy Morgan Research']\n"
     ]
    }
   ],
   "source": [
    "url = 'https://www.seek.com.au/job/38952572?type=standout&searchrequesttoken=ea2e6044-6c97-4e94-84c7-54a6b29c449f'\n",
    "job_title, advertiser, rating, posted_date, salary, type_of_work, category_of_work, sub_category_of_work, body_of_text = page(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title, advertiser, rating, posted_date, salary, type_of_work, category_of_work, sub_category_of_work, body_of_text;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Search Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_df = jobs_scraped('data-scientist', 'All-Melbourne-VIC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sydney = jobs_scraped('data-scientist', 'All-Sydney-NSW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_sydney.to_csv('seek_ds_Sydney.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(ds_sydney);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'https://www.seek.com.au/job/38866940?searchrequesttoken=1627f2be-df19-4f82-9a3b-02d0b8c87149&type=promoted'\n",
    "job_title, advertiser, rating, posted_date, salary, type_of_work, category_of_work, sub_category_of_work, body_of_text = page(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "job_title, advertiser, rating, posted_date, salary, type_of_work, category_of_work, sub_category_of_work, body_of_text;"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving original scraped data to csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_df.to_csv('seek_datascientist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_sydney = jobs_scraped('data-analyst', 'All-Sydney-NSW')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "da_sydney.to_csv('seek_da_Sydney.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_df = jobs_scraped('data-analyst', 'All-Melbourne-VIC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_df.to_csv('seek_data-analyst.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('seek_data-analyst.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_ds = pd.read_csv('seek_datascientist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sydney_DA= pd.read_csv('seek_da_Sydney.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4004, 13) (180, 13) (3158, 13) (100, 13)\n"
     ]
    }
   ],
   "source": [
    "print(Sydney_DA.shape, Sydney_DS.shape, Mel_DA.shape, Mel_DS.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sydney_DS = pd.read_csv('seek_ds_Sydney.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mel_DS = pd.read_csv('seek_datascientist.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "Mel_DA = pd.read_csv('seek_data-analyst.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Concatinating 4 csv's to a DF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_jobs = pd.concat([Sydney_DA,Sydney_DS,Mel_DS,Mel_DA], ignore_index= True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
